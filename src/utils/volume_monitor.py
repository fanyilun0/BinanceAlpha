"""
äº¤æ˜“é‡å˜åŒ–ç›‘æ§æ¨¡å—

ç›‘æ§åŠ å¯†è´§å¸äº¤æ˜“é‡å˜åŒ–å¹¶å‘é€è­¦æŠ¥
æ”¯æŒä¸‰æ—¥è¶‹åŠ¿åˆ†æï¼šæ¢æ‰‹ç‡ç¨³å®šæ€§ã€å¸ç­¹ã€æ´—ç›˜æ£€æµ‹
ç‹¬ç«‹æ¨¡å—ï¼Œå¯ç›´æ¥è¿è¡Œ
"""

import asyncio
import logging
import json
import os
import sys
from datetime import datetime, timedelta
from dataclasses import dataclass
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½• to sys.path so we can import config and webhook
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.append(project_root)

from config import DATA_DIRS
from src.utils.discord_webhook import send_discord_message, send_discord_embed, DiscordColors

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('volume_monitor.log', mode='a')
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class TrendSignal:
    """ä¸‰æ—¥è¶‹åŠ¿åˆ†æä¿¡å·"""
    signal_type: str  # ACCUMULATION_STABLE, WASH_COMPLETE, NEUTRAL
    score: float  # 0-1 ç½®ä¿¡åº¦
    reason: str
    details: dict = None
    # ä¸‰æ—¥æ•°æ® (ç”¨äºå±•ç¤º)
    history_3d: list = None  # [T0, T-1, T-2] æ¯é¡¹åŒ…å« volume, price, market_cap, turnover


@dataclass
class MarketTierConfig:
    """ä¸åŒå¸‚å€¼å±‚çº§çš„åŠ¨æ€é˜ˆå€¼é…ç½®"""
    name: str
    min_mcap: float
    max_cv: float          # å…è®¸çš„æœ€å¤§äº¤æ˜“é‡å˜å¼‚ç³»æ•° (è¶Šå°è¶Šä¸¥)
    max_price_dev: float   # å…è®¸çš„æœ€å¤§ä»·æ ¼åå·® (%, Â±å€¼)
    min_turnover: float    # æœ€ä½æ¢æ‰‹ç‡è¦æ±‚
    vol_weight: float      # äº¤æ˜“é‡æƒé‡
    price_weight: float    # ä»·æ ¼æƒé‡


# å®šä¹‰åˆ†å±‚é…ç½®
MARKET_TIERS: list[MarketTierConfig] = [
    MarketTierConfig("LARGE", 100_000_000, max_cv=0.10, max_price_dev=2.0, min_turnover=0.01, vol_weight=0.5, price_weight=0.5),
    MarketTierConfig("MID",   10_000_000, max_cv=0.18, max_price_dev=4.0, min_turnover=0.02, vol_weight=0.4, price_weight=0.6),
    MarketTierConfig("SMALL",  5_000_000, max_cv=0.30, max_price_dev=8.0, min_turnover=0.03, vol_weight=0.3, price_weight=0.7),
]


class ScoringConfig:
    """è¯„åˆ†ä¸é£æ§é…ç½®"""
    # å¸‚å€¼é—¨æ§› (å•ä½: USD)
    MIN_MCAP_THRESHOLD = 1_000_000         # 1M: ä½äºæ­¤å€¼ç›´æ¥å¿½ç•¥
    TARGET_MCAP_MIN = 10_000_000           # 10M: é‡ç‚¹å…³æ³¨ä¸‹é™
    TARGET_MCAP_MAX = 100_000_000          # 100M: é‡ç‚¹å…³æ³¨ä¸Šé™

    # ==========================================
    # ä¼˜åŒ–: æé«˜ç¡¬æ€§è¿‡æ»¤é—¨æ§›ï¼Œå‰”é™¤å™ªéŸ³
    # ==========================================
    MIN_VOLUME_24H = 3_000_000             # 3M: æœ€ä½24häº¤æ˜“é‡é—¨æ§› (åŸ2.4M)
    MIN_TURNOVER = 0.02                    # 2%: æœ€ä½æ¢æ‰‹ç‡ï¼Œå‰”é™¤æ­»ç›˜
    
    # æ¢æ‰‹ç‡å¥åº·åŒºé—´
    TURNOVER_HEALTHY_MIN = 0.03            # 3%: ä½äºæ­¤å€¼æµåŠ¨æ€§å·®
    TURNOVER_HEALTHY_MAX = 0.30            # 30%: é«˜äºæ­¤å€¼å¯èƒ½è¿‡çƒ­/P&Dé£é™©

    # æƒé‡é…ç½®
    WEIGHT_PATTERN = 0.6                   # å½¢æ€æƒé‡ (æŠ€æœ¯é¢)
    WEIGHT_MCAP = 0.3                      # å¸‚å€¼æƒé‡ (ç­–ç•¥é¢)
    WEIGHT_LIQUIDITY = 0.1                 # æµåŠ¨æ€§æƒé‡ (èµ„é‡‘é¢)


class ConfidenceEngine:
    """ç½®ä¿¡åº¦è®¡ç®—å¼•æ“
    
    åŸºäºå¸‚å€¼åˆ†å±‚å’Œæ¢æ‰‹ç‡å¥åº·åº¦ï¼Œå¯¹åŸºç¡€å½¢æ€åˆ†æ•°è¿›è¡ŒåŠ æƒè°ƒæ•´ã€‚
    é‡ç‚¹å…³æ³¨ 10M-100M é»„é‡‘åŒºé—´ï¼Œè¿‡æ»¤ <1M åƒåœ¾ç›˜ã€‚
    """

    @staticmethod
    def calculate_score(base_score: float, market_cap: float, turnover: float) -> tuple[float, str]:
        """è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
        
        Args:
            base_score: åŸºç¡€å½¢æ€åˆ†æ•° (0-1)
            market_cap: å¸‚å€¼ (USD)
            turnover: æ¢æ‰‹ç‡ (0-1)
            
        Returns:
            (final_score, mcap_tag): æœ€ç»ˆåˆ†æ•°å’Œå¸‚å€¼æ ‡ç­¾
        """
        # 1. å¸‚å€¼ç³»æ•° (Market Cap Multiplier)
        mcap_score = 1.0
        mcap_tag = ""

        if ScoringConfig.TARGET_MCAP_MIN <= market_cap <= ScoringConfig.TARGET_MCAP_MAX:
            # é»„é‡‘åŒºé—´ (10M-100M): ç»™äºˆåŠ æˆ
            mcap_score = 1.2
            mcap_tag = "[é»„é‡‘å¸‚å€¼]"
        elif market_cap > ScoringConfig.TARGET_MCAP_MAX:
            # å¤§å¸‚å€¼: ä¿æŒæ ‡å‡†
            mcap_score = 1.0
            mcap_tag = "[å¤§å¸‚å€¼ç¨³å¥]"
        elif market_cap >= 5_000_000:
            # å°å¸‚å€¼ (5M-10M): é™æƒ
            mcap_score = 0.85
            mcap_tag = "[å°å¸‚å€¼é«˜é£]"
        else:
            # å¾®å‹å¸‚å€¼ (1M-5M): é‡åº¦é™æƒ
            mcap_score = 0.7
            mcap_tag = "[å¾®å‹å¸‚å€¼]"

        # 2. æ¢æ‰‹ç‡ä¿®æ­£ (Turnover Correction)
        # ä½¿ç”¨æ­£æ€åˆ†å¸ƒé€»è¾‘ï¼Œä¸­é—´ä¼˜ï¼Œä¸¤å¤´å·®
        turnover_score = 1.0
        if turnover < ScoringConfig.TURNOVER_HEALTHY_MIN:
            turnover_score = 0.7  # æµåŠ¨æ€§ä¸è¶³
        elif turnover > ScoringConfig.TURNOVER_HEALTHY_MAX:
            turnover_score = 0.8  # è¿‡çƒ­é£é™©
        else:
            turnover_score = 1.1  # å¥åº·æ¢æ‰‹

        # 3. ç»¼åˆè®¡ç®—
        # åŸºç¡€åˆ† * å¸‚å€¼ç³»æ•° * æ¢æ‰‹ä¿®æ­£ (é™åˆ¶æœ€å¤§å€¼ä¸º 0.99)
        raw_final = base_score * mcap_score * turnover_score
        final_score = min(0.99, raw_final)

        return final_score, mcap_tag

    @staticmethod
    def get_score_emoji(score: float) -> str:
        """æ ¹æ®ç½®ä¿¡åº¦è¿”å› Emoji"""
        if score >= 0.9:
            return "ğŸ”¥"  # æé«˜ç½®ä¿¡åº¦ (é€šå¸¸æ˜¯é»„é‡‘å¸‚å€¼+å®Œç¾å½¢æ€)
        if score >= 0.8:
            return "â­"  # é«˜ç½®ä¿¡åº¦
        if score >= 0.7:
            return "ğŸ”¹"  # ä¸­ç­‰ç½®ä¿¡åº¦
        return "âšª"  # ä½ç½®ä¿¡åº¦


# ==============================================================================
# SignalArbiter: ä¿¡å·ä»²è£å™¨ - å®ç°"èµ¢å®¶é€šåƒ"å»é‡é€»è¾‘
# ==============================================================================

class SignalCategory:
    """ä¿¡å·åˆ†ç±»æšä¸¾"""
    ALPHA_TREND = "alpha_trend"           # ğŸ¯ Alpha: å®Œç¾ä¸‰æ—¥è¶‹åŠ¿
    ALPHA_WHALE = "alpha_whale"           # ğŸ¯ Alpha: å·¨é²¸å¸ç­¹
    RISK_DISTRIBUTION = "risk_distribution"  # âš ï¸ é£é™©: ä¸»åŠ›å‡ºè´§
    ANOMALY_EXTREME = "anomaly_extreme"   # âš ï¸ å¼‚åŠ¨: æç«¯çˆ†é‡


@dataclass
class ClassifiedSignal:
    """åˆ†ç±»åçš„ä¿¡å·"""
    symbol: str
    name: str
    category: str           # SignalCategory
    sub_type: str           # ç»†åˆ†ç±»å‹: ACCUMULATION_STABLE, WASH_COMPLETE, BULL_FLAG, etc.
    score: float            # ç½®ä¿¡åº¦ 0-1
    mcap_tag: str           # å¸‚å€¼æ ‡ç­¾
    data: dict              # åŸå§‹æ•°æ®
    reason: str             # ä¿¡å·åŸå› 


class SignalArbiter:
    """ä¿¡å·ä»²è£å™¨
    
    æ ¸å¿ƒèŒè´£ï¼š
    1. æŒ‰ä¼˜å…ˆçº§é¡ºåºåˆ¤å®šæ¯ä¸ªä»£å¸çš„æœ€ç»ˆåˆ†ç±»
    2. å®ç°"èµ¢å®¶é€šåƒ"ï¼šä¸€ä¸ªä»£å¸åªèƒ½å½’å…¥ä¸€ä¸ªç±»åˆ«
    3. è¾“å‡ºä¸¤æ¡æ•°æ®æµï¼šğŸ¯ Alpha + âš ï¸ å¼‚åŠ¨
    
    ä¼˜å…ˆçº§é¡ºåºï¼š
    1. Trend (å®Œç¾ä¸‰æ—¥è¶‹åŠ¿) â†’ Alpha
    2. Accumulation (å¼ºåŠ›å¸ç­¹, score > 0.8) â†’ Alpha  
    3. Distribution (å‡ºè´§) â†’ å¼‚åŠ¨/é£é™©
    4. Extreme Vol (æç«¯æ³¢åŠ¨) â†’ å¼‚åŠ¨
    """
    
    # é˜ˆå€¼é…ç½®
    ALPHA_WHALE_MIN_SCORE = 0.80          # å·¨é²¸å¸ç­¹æœ€ä½åˆ†
    EXTREME_VOL_MIN_CHANGE = 100          # æç«¯çˆ†é‡æœ€ä½å˜åŒ–ç‡ (%)
    EXTREME_VOL_MIN_TURNOVER = 0.05       # æç«¯çˆ†é‡æœ€ä½æ¢æ‰‹ç‡ (5%)
    
    def __init__(self):
        self.alpha_signals: list[ClassifiedSignal] = []
        self.anomaly_signals: list[ClassifiedSignal] = []
        self._processed_symbols: set[str] = set()
    
    def classify(
        self,
        trend_signals: list[dict],
        accumulation_alerts: list[dict],
        distribution_alerts: list[dict],
        volume_alerts: list[dict]
    ) -> tuple[list[ClassifiedSignal], list[ClassifiedSignal]]:
        """æ‰§è¡Œåˆ†ç±»ä»²è£
        
        Args:
            trend_signals: ä¸‰æ—¥è¶‹åŠ¿ä¿¡å·
            accumulation_alerts: å¸ç­¹å‘Šè­¦
            distribution_alerts: å‡ºè´§å‘Šè­¦
            volume_alerts: å¸¸è§„äº¤æ˜“é‡å¼‚åŠ¨
            
        Returns:
            (alpha_signals, anomaly_signals)
        """
        self.alpha_signals.clear()
        self.anomaly_signals.clear()
        self._processed_symbols.clear()
        
        # ========================================
        # Priority 1: å®Œç¾ä¸‰æ—¥è¶‹åŠ¿ â†’ Alpha
        # ========================================
        for item in trend_signals:
            symbol = item.get("symbol", "")
            if not symbol or symbol in self._processed_symbols:
                continue
            
            signal = ClassifiedSignal(
                symbol=symbol,
                name=item.get("name", ""),
                category=SignalCategory.ALPHA_TREND,
                sub_type=item.get("signal_type", "TREND"),
                score=item.get("score", 0),
                mcap_tag=item.get("details", {}).get("mcap_tag", "") if item.get("details") else "",
                data=item,
                reason=item.get("reason", "ä¸‰æ—¥è¶‹åŠ¿ä¿¡å·")
            )
            self.alpha_signals.append(signal)
            self._processed_symbols.add(symbol)
        
        # ========================================
        # Priority 2: å¼ºåŠ›å¸ç­¹ (é«˜åˆ†) â†’ Alpha
        # ========================================
        for item in accumulation_alerts:
            symbol = item.get("symbol", "")
            if not symbol or symbol in self._processed_symbols:
                continue
            
            score = item.get("score", 0)
            # åªæœ‰é«˜åˆ†å¸ç­¹æ‰è¿›å…¥ Alpha
            if score >= self.ALPHA_WHALE_MIN_SCORE or item.get("is_continuous"):
                reason = "å·¨é²¸å¸ç­¹ (é‡å¢ä»·å¹³)"
                if item.get("is_continuous"):
                    reason += " + è¿ç»­3æ—¥ç¨³å®š"
                signal = ClassifiedSignal(
                    symbol=symbol,
                    name=item.get("name", ""),
                    category=SignalCategory.ALPHA_WHALE,
                    sub_type="ACCUMULATION_WHALE",
                    score=score,
                    mcap_tag=item.get("mcap_tag", ""),
                    data=item,
                    reason=reason
                )
                self.alpha_signals.append(signal)
                self._processed_symbols.add(symbol)
        
        # ========================================
        # Priority 3: ä¸»åŠ›å‡ºè´§ â†’ å¼‚åŠ¨/é£é™©
        # ========================================
        for item in distribution_alerts:
            symbol = item.get("symbol", "")
            if not symbol or symbol in self._processed_symbols:
                continue
            
            signal = ClassifiedSignal(
                symbol=symbol,
                name=item.get("name", ""),
                category=SignalCategory.RISK_DISTRIBUTION,
                sub_type="DISTRIBUTION",
                score=item.get("score", 0.65),
                mcap_tag=item.get("mcap_tag", ""),
                data=item,
                reason=f"æ”¾é‡ä¸‹è·Œ {item.get('price_change', 0):+.1f}%"
            )
            self.anomaly_signals.append(signal)
            self._processed_symbols.add(symbol)
        
        # ========================================
        # Priority 4: ä½åˆ†å¸ç­¹ â†’ å¼‚åŠ¨
        # ========================================
        for item in accumulation_alerts:
            symbol = item.get("symbol", "")
            if not symbol or symbol in self._processed_symbols:
                continue
            
            score = item.get("score", 0)
            # ä½åˆ†å¸ç­¹è¿›å…¥å¼‚åŠ¨
            signal = ClassifiedSignal(
                symbol=symbol,
                name=item.get("name", ""),
                category=SignalCategory.ANOMALY_EXTREME,
                sub_type="ACCUMULATION_SINGLE",
                score=score,
                mcap_tag=item.get("mcap_tag", ""),
                data=item,
                reason=f"å•æ—¥å¸ç­¹ (Vol+{item.get('vol_change', 0):.0f}%)"
            )
            self.anomaly_signals.append(signal)
            self._processed_symbols.add(symbol)
        
        # ========================================
        # Priority 5: æç«¯äº¤æ˜“é‡å¼‚åŠ¨ â†’ å¼‚åŠ¨
        # ========================================
        for item in volume_alerts:
            symbol = item.get("symbol", "")
            if not symbol or symbol in self._processed_symbols:
                continue
            
            change = abs(item.get("change_24h", 0))
            turnover = item.get("volume_24h", 0) / item.get("market_cap", 1) if item.get("market_cap", 0) > 0 else 0
            
            # åªä¿ç•™æç«¯å¼‚åŠ¨
            if change >= self.EXTREME_VOL_MIN_CHANGE and turnover >= self.EXTREME_VOL_MIN_TURNOVER:
                price_change = item.get("price_change", 0)
                if price_change > 10:
                    reason = "ğŸ”¥ æ”¾é‡ä¸Šæ¶¨"
                elif price_change < -5:
                    reason = "âš ï¸ æ”¾é‡ä¸‹è·Œ"
                else:
                    reason = "ğŸ“Š æç«¯çˆ†é‡"
                
                signal = ClassifiedSignal(
                    symbol=symbol,
                    name=item.get("name", ""),
                    category=SignalCategory.ANOMALY_EXTREME,
                    sub_type="EXTREME_VOLUME",
                    score=0.5,  # æç«¯çˆ†é‡åŸºç¡€åˆ†è¾ƒä½
                    mcap_tag="",
                    data=item,
                    reason=reason
                )
                self.anomaly_signals.append(signal)
                self._processed_symbols.add(symbol)
        
        # æ’åºï¼šæŒ‰ score desc, market_cap desc
        self.alpha_signals.sort(key=lambda x: (x.score, x.data.get("market_cap", 0)), reverse=True)
        self.anomaly_signals.sort(key=lambda x: (x.score, x.data.get("market_cap", 0)), reverse=True)
        
        return self.alpha_signals, self.anomaly_signals
    
    def get_stats(self) -> dict:
        """è·å–åˆ†ç±»ç»Ÿè®¡"""
        alpha_by_type = {}
        for s in self.alpha_signals:
            alpha_by_type[s.sub_type] = alpha_by_type.get(s.sub_type, 0) + 1
        
        anomaly_by_type = {}
        for s in self.anomaly_signals:
            anomaly_by_type[s.sub_type] = anomaly_by_type.get(s.sub_type, 0) + 1
        
        return {
            "alpha_total": len(self.alpha_signals),
            "alpha_by_type": alpha_by_type,
            "anomaly_total": len(self.anomaly_signals),
            "anomaly_by_type": anomaly_by_type,
            "processed_symbols": len(self._processed_symbols)
        }


class DynamicTrendAnalyzer:
    """åŸºäºå¸‚å€¼åˆ†å±‚çš„åŠ¨æ€è¶‹åŠ¿åˆ†æå™¨
    
    æ ¸å¿ƒæ”¹è¿›:
    1. åŠ¨æ€é˜ˆå€¼ï¼šæ ¹æ®å¸‚å€¼åˆ†å±‚è°ƒæ•´ CV/ä»·æ ¼åå·®å®¹å¿åº¦
    2. åŠ æƒè¯„åˆ†ï¼šé›†æˆ ConfidenceEngine è¿›è¡Œå¸‚å€¼åˆ†å±‚åŠ æƒ
    3. å¤šç­–ç•¥æ£€æµ‹ï¼šå¸ç­¹ã€æ´—ç›˜ç»“æŸã€ç‰›æ——æ•´ç†
    """

    @staticmethod
    def _get_tier(market_cap: float) -> MarketTierConfig:
        """æ ¹æ®å¸‚å€¼è·å–å¯¹åº”å±‚çº§çš„é…ç½®"""
        for tier in MARKET_TIERS:
            if market_cap >= tier.min_mcap:
                return tier
        return MARKET_TIERS[-1]

    @staticmethod
    def _normalize_score(value: float, threshold: float, inverse: bool = True) -> float:
        """å½’ä¸€åŒ–æ‰“åˆ†å‡½æ•° (0-1)
        inverse=True: å€¼è¶Šå°åˆ†è¶Šé«˜ (å¦‚CV)
        inverse=False: å€¼è¶Šå¤§åˆ†è¶Šé«˜ (å¦‚æ¢æ‰‹ç‡)
        """
        if inverse:
            if value >= threshold:
                return 0.0
            return 1.0 - (value / threshold)
        if value >= threshold:
            return 1.0
        return min(value / threshold, 1.0)

    @staticmethod
    def analyze(history_3d: list[dict]) -> Optional[TrendSignal]:
        """åˆ†æä¸‰æ—¥è¶‹åŠ¿å¹¶è¿”å›ä¿¡å·
        
        Args:
            history_3d: ä¸‰æ—¥æ•°æ®åˆ—è¡¨ [T0, T-1, T-2]ï¼Œæ¯é¡¹åŒ…å« volume, price, market_cap
            
        Returns:
            TrendSignal æˆ– None
        """
        if len(history_3d) < 3:
            return None

        d0, d1, d2 = history_3d[0], history_3d[1], history_3d[2]
        volumes = [d['volume'] for d in history_3d]
        prices = [d['price'] for d in history_3d]
        market_cap = d0.get("market_cap", 0)

        # è·å–è¯¥å¸ç§çš„åŠ¨æ€é˜ˆå€¼é…ç½®
        config = DynamicTrendAnalyzer._get_tier(market_cap)

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        vol_mean = sum(volumes) / 3
        vol_std = (sum((v - vol_mean) ** 2 for v in volumes) / 3) ** 0.5
        vol_cv = vol_std / vol_mean if vol_mean > 0 else float('inf')

        # ä»·æ ¼å˜åŒ–åºåˆ—
        p_changes = [
            ((prices[0] - prices[1]) / prices[1] * 100) if prices[1] else 0,
            ((prices[1] - prices[2]) / prices[2] * 100) if prices[2] else 0
        ]
        max_p_change = max(abs(c) for c in p_changes)

        # æ¢æ‰‹ç‡
        avg_turnover = sum(d.get("volume", 0) / d.get("market_cap", 1) for d in history_3d) / 3
        current_turnover = d0.get("volume", 0) / market_cap if market_cap > 0 else 0

        # æ„å»ºè¿”å›ç”¨çš„å†å²æ•°æ®
        history_enriched = []
        for d in history_3d:
            history_enriched.append({
                "volume": d["volume"],
                "price": d["price"],
                "market_cap": d.get("market_cap", 0),
                "turnover": d.get("volume", 0) / d.get("market_cap", 1) if d.get("market_cap") else 0
            })

        # ==========================================
        # ç­–ç•¥ A: æ™ºèƒ½å¸ç­¹æ£€æµ‹ (Accumulation)
        # ==========================================
        # é€»è¾‘ï¼šä»·æ ¼è¦åœ¨åŠ¨æ€é˜ˆå€¼å†…æ¨ªç›˜ï¼Œä¸”é‡èƒ½ç¨³å®š

        # A1. é‡èƒ½ç¨³å®šæ€§å¾—åˆ† (CVè¶Šä½åˆ†è¶Šé«˜)
        score_vol_stability = DynamicTrendAnalyzer._normalize_score(vol_cv, config.max_cv, inverse=True)

        # A2. ä»·æ ¼æ¨ªç›˜å¾—åˆ† (å˜åŒ–å¹…åº¦è¶Šå°åˆ†è¶Šé«˜)
        score_price_flat = DynamicTrendAnalyzer._normalize_score(max_p_change, config.max_price_dev, inverse=True)

        # A3. æ´»è·ƒåº¦æƒ©ç½š (å¦‚æœæ˜¯æ­»ç›˜ï¼Œç›´æ¥æ‰£åˆ†)
        active_ratio = min(avg_turnover / config.min_turnover, 1.0) if config.min_turnover > 0 else 0

        # åŸºç¡€å½¢æ€åˆ†æ•° (åŠ æƒ)
        base_accumulation_score = (
            score_vol_stability * config.vol_weight +
            score_price_flat * config.price_weight
        ) * active_ratio

        if base_accumulation_score > 0.60:  # åŸºç¡€é—¨æ§›é™ä½ï¼Œè®© ConfidenceEngine å†³å®šæœ€ç»ˆåˆ†æ•°
            # ä½¿ç”¨ ConfidenceEngine è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
            final_score, mcap_tag = ConfidenceEngine.calculate_score(
                base_accumulation_score, market_cap, current_turnover
            )

            # æœ€ç»ˆåˆ†æ•°è¿‡æ»¤
            if final_score >= 0.60:
                return TrendSignal(
                    signal_type="ACCUMULATION_STABLE",
                    score=round(final_score, 2),
                    reason=f"[{config.name}] é‡ç¨³({score_vol_stability:.2f}) ä»·å¹³({score_price_flat:.2f})",
                    details={
                        "tier": config.name,
                        "mcap_tag": mcap_tag,
                        "vol_cv": round(vol_cv, 4),
                        "max_p_change": round(max_p_change, 2),
                        "avg_turnover": round(avg_turnover, 4),
                        "base_score": round(base_accumulation_score, 2)
                    },
                    history_3d=history_enriched
                )

        # ==========================================
        # ç­–ç•¥ B: æ´—ç›˜ç»“æŸ (Wash Complete)
        # ==========================================
        # é€»è¾‘ï¼šè¿ç»­ç¼©é‡ + ä»·æ ¼ä¼ç¨³

        # B1. ç¼©é‡å¾—åˆ† (ä»Šå¤©<æ˜¨å¤©<å‰å¤©)
        is_shrinking = volumes[0] < volumes[1] < volumes[2]
        shrink_magnitude = (volumes[2] - volumes[0]) / volumes[2] if volumes[2] > 0 else 0
        score_shrink = 0.8 if is_shrinking else 0.0
        if is_shrinking and 0.3 <= shrink_magnitude <= 0.7:
            # å¦‚æœç¼©é‡å¹…åº¦åœ¨ 30%-70% ä¹‹é—´ï¼ŒåŠ åˆ† (ç¼©å¤ªå°‘æ²¡æ„ä¹‰ï¼Œç¼©å¤ªå¤šå¯èƒ½æ˜¯å½’é›¶)
            score_shrink += 0.2

        # B2. ä¼ç¨³å¾—åˆ† (ä»Šå¤©ä»·æ ¼æ²¡è·Œ æˆ– å¾®è·Œ)
        # å®¹å¿å¾®è·Œ -1.5% åˆ° +inf
        score_stabilize = 1.0 if p_changes[0] > -1.5 else 0.0

        base_wash_score = (score_shrink * 0.6 + score_stabilize * 0.4)

        if base_wash_score > 0.70:
            # ä½¿ç”¨ ConfidenceEngine è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
            final_score, mcap_tag = ConfidenceEngine.calculate_score(
                base_wash_score, market_cap, current_turnover
            )

            if final_score >= 0.60:
                return TrendSignal(
                    signal_type="WASH_COMPLETE",
                    score=round(final_score, 2),
                    reason=f"[{config.name}] è¿ç»­ç¼©é‡({shrink_magnitude*100:.1f}%)ä¸”ä»·æ ¼ä¼ç¨³",
                    details={
                        "tier": config.name,
                        "mcap_tag": mcap_tag,
                        "shrink_mag": round(shrink_magnitude, 4),
                        "base_score": round(base_wash_score, 2)
                    },
                    history_3d=history_enriched
                )

        # ==========================================
        # ç­–ç•¥ C: ç‰›æ——æ•´ç† (Bull Flag)
        # ==========================================
        # é€»è¾‘ï¼šå‰æ—¥æ”¾é‡å¤§æ¶¨ + æ˜¨æ—¥/ä»Šæ—¥ç¼©é‡å›è°ƒ

        # C1. å‰æ—¥æ˜¯å¦æ”¾é‡å¤§æ¶¨
        is_prev_pump = (
            p_changes[1] > 10 and  # T-2 åˆ° T-1 æ¶¨å¹… > 10%
            volumes[1] > volumes[2] * 1.5  # T-1 é‡èƒ½ > T-2 * 1.5
        )

        # C2. ä»Šæ—¥æ˜¯å¦ç¼©é‡æ•´ç†
        is_now_correction = (
            -5 < p_changes[0] < 5 and  # T-1 åˆ° T0 æ³¢åŠ¨ < Â±5%
            volumes[0] < volumes[1] * 0.7  # T0 é‡èƒ½ < T-1 * 0.7
        )

        if is_prev_pump and is_now_correction:
            base_flag_score = 0.75
            final_score, mcap_tag = ConfidenceEngine.calculate_score(
                base_flag_score, market_cap, current_turnover
            )

            if final_score >= 0.60:
                return TrendSignal(
                    signal_type="BULL_FLAG",
                    score=round(final_score, 2),
                    reason=f"[{config.name}] æ˜¨æ—¥æ”¾é‡æ¶¨{p_changes[1]:.1f}%ï¼Œä»Šæ—¥ç¼©é‡æ•´ç†",
                    details={
                        "tier": config.name,
                        "mcap_tag": mcap_tag,
                        "prev_pump_pct": round(p_changes[1], 2),
                        "vol_shrink_ratio": round(volumes[0] / volumes[1], 2) if volumes[1] > 0 else 0,
                        "base_score": round(base_flag_score, 2)
                    },
                    history_3d=history_enriched
                )

        return TrendSignal(
            signal_type="NEUTRAL",
            score=0.1,
            reason="æ— æ˜æ˜¾ç‰¹å¾",
            details={"tier": config.name, "vol_cv": round(vol_cv, 4)},
            history_3d=history_enriched
        )

def _find_latest_file_for_date(data_dir: str, target_date: str) -> Optional[str]:
    """æŸ¥æ‰¾æŒ‡å®šæ—¥æœŸçš„æœ€æ–°æ•°æ®æ–‡ä»¶
    
    Args:
        data_dir: æ•°æ®ç›®å½•
        target_date: ç›®æ ‡æ—¥æœŸ (YYYYMMDD æ ¼å¼)
        
    Returns:
        æœ€æ–°æ–‡ä»¶è·¯å¾„æˆ–None
    """
    import glob
    pattern = os.path.join(data_dir, f'filtered_crypto_list_{target_date}*.json')
    files = glob.glob(pattern)
    
    if not files:
        return None
    
    # æŒ‰æ–‡ä»¶åæ’åºï¼Œå–æœ€æ–°çš„ï¼ˆæ—¶é—´æˆ³æœ€å¤§çš„ï¼‰
    files.sort(reverse=True)
    return files[0]


def load_multi_day_data(days: int = 3) -> dict[str, list]:
    """åŠ è½½æœ€è¿‘Nå¤©çš„ filtered_crypto_list æ•°æ®
    
    Args:
        days: éœ€è¦åŠ è½½çš„å¤©æ•°ï¼ˆé»˜è®¤3å¤©ï¼‰
        
    Returns:
        dict: {
            "T0": [crypto_list],  # ä»Šå¤©
            "T-1": [crypto_list], # æ˜¨å¤©
            "T-2": [crypto_list], # å‰å¤©
            ...
        }
    """
    data_dir = os.path.join(project_root, 'data')
    result = {}
    
    for i in range(days):
        date_obj = datetime.now() - timedelta(days=i)
        date_str = date_obj.strftime('%Y%m%d')
        key = f"T{-i}" if i > 0 else "T0"
        
        file_path = _find_latest_file_for_date(data_dir, date_str)
        
        if file_path and os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    result[key] = data
                    logger.info(f"å·²åŠ è½½ {key} ({date_str}) æ•°æ®: {os.path.basename(file_path)}, å…± {len(data)} é¡¹")
            except Exception as e:
                logger.error(f"åŠ è½½ {key} ({date_str}) æ•°æ®å¤±è´¥: {str(e)}")
                result[key] = []
        else:
            logger.warning(f"æœªæ‰¾åˆ° {key} ({date_str}) çš„æ•°æ®æ–‡ä»¶")
            result[key] = []
    
    return result


def _build_crypto_index(crypto_list: list) -> dict[str, dict]:
    """æ„å»º symbol -> crypto_data çš„ç´¢å¼•
    
    Args:
        crypto_list: åŠ å¯†è´§å¸åˆ—è¡¨
        
    Returns:
        dict: {symbol: crypto_data}
    """
    index = {}
    for crypto in crypto_list:
        symbol = crypto.get("symbol", "")
        if symbol:
            index[symbol] = crypto
    return index


def load_data():
    """åŠ è½½æœ€æ–°çš„Binance Alphaæ•°æ® (å…¼å®¹åŸæœ‰æ¥å£)
    
    Returns:
        ä»Šå¤©çš„æ•°æ®ï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰æˆ– None
    """
    multi_day = load_multi_day_data(days=1)
    today_data = multi_day.get("T0", [])
    
    if not today_data:
        logger.error("åŠ è½½ä»Šæ—¥æ•°æ®å¤±è´¥")
        return None
    
    # å…¼å®¹åŸæœ‰æ ¼å¼
    return {
        "data": {
            "cryptoCurrencyList": today_data
        }
    }


async def monitor_volume_changes(crypto_list=None, threshold=50.0, debug_only=False):
    """ç›‘æ§äº¤æ˜“é‡å˜åŒ–å¹¶å‘é€è­¦æŠ¥
    
    æµç¨‹ï¼š
    1. ç¡¬æ€§å¸‚å€¼è¿‡æ»¤
    2. æ‰¹é‡å¤„ç†æ‰€æœ‰é¡¹ç›®ï¼Œæ›´æ–°ä»Šæ—¥æ•°æ®
    3. åŸºäºä¸‰æ—¥å†å²æ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æ
    4. ç½®ä¿¡åº¦åŠ æƒ
    5. æ™ºèƒ½æ’åºå¹¶å‘é€å‘Šè­¦
    """
    print(f"=== ç›‘æ§äº¤æ˜“é‡å˜åŒ– (é˜ˆå€¼: {threshold}%) ===\n")
    
    # åˆå§‹åŒ–å†å²æ•°æ®ç®¡ç†å™¨
    history_manager = HistoryManager(os.path.join(project_root, 'data'))
    today_str = datetime.now().strftime('%Y-%m-%d')
    yesterday_str = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    day_before_str = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')
    three_days_ago_str = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')
    
    # åŠ è½½4å¤©æ•°æ®æ–‡ä»¶ (T0, T-1, T-2, T-3)
    # T-3 ç”¨äºè®¡ç®— T-2 çš„ä»·æ ¼æ¶¨è·Œå¹…
    multi_day_data = load_multi_day_data(days=4)
    t0_list = multi_day_data.get("T0", [])
    t1_list = multi_day_data.get("T-1", [])
    t2_list = multi_day_data.get("T-2", [])
    t3_list = multi_day_data.get("T-3", [])
    
    # æ„å»ºç´¢å¼•
    t1_index = _build_crypto_index(t1_list)
    t2_index = _build_crypto_index(t2_list)
    t3_index = _build_crypto_index(t3_list)
    
    if crypto_list is None:
        if not t0_list:
            print("æ— æ³•åŠ è½½æ•°æ®ï¼Œç›‘æ§ç»ˆæ­¢")
            return {"alerts": [], "triggered_count": 0}
        crypto_list = t0_list
        print(f"å·²åŠ è½½ {len(crypto_list)} ä¸ªé¡¹ç›®æ•°æ®")

    # ä½¿ç”¨ç»Ÿä¸€é…ç½®çš„äº¤æ˜“é‡é—¨æ§›
    MIN_VOLUME_24H = ScoringConfig.MIN_VOLUME_24H
    
    # ============================================
    # é˜¶æ®µ1: ç¡¬æ€§è¿‡æ»¤ + æ‰¹é‡æ›´æ–°ä»Šæ—¥æ•°æ®
    # ============================================
    print("é˜¶æ®µ1: ç¡¬æ€§è¿‡æ»¤åŠæ‰¹é‡æ›´æ–°ä»Šæ—¥æ•°æ®...")
    processed_symbols = []
    valid_crypto_list = []  # ç”¨äºåç»­åˆ†æçš„æ¸…æ´—ååˆ—è¡¨
    filtered_count = 0
    
    for crypto in crypto_list:
        symbol = crypto.get("symbol", "Unknown")
        quotes = crypto.get("quotes", [])
        usd_quote = next((q for q in quotes if q.get("name") == "USD"), {})
        if not usd_quote and len(quotes) > 2:
            usd_quote = quotes[2]
        
        if not usd_quote:
            continue
        
        volume_24h = usd_quote.get("volume24h", 0)
        price = usd_quote.get("price", 0)
        market_cap = usd_quote.get("marketCap", 0)
        
        # ---> ç¡¬æ€§è¿‡æ»¤ (ä¼˜åŒ–: å¢åŠ äº¤æ˜“é‡å’Œæ¢æ‰‹ç‡é—¨æ§›) <---
        # 1. å¸‚å€¼è¿‡æ»¤
        if market_cap < ScoringConfig.MIN_MCAP_THRESHOLD:
            filtered_count += 1
            continue  # ç›´æ¥è·³è¿‡ < 1M çš„ä»£å¸
        
        # 2. äº¤æ˜“é‡è¿‡æ»¤ (æ–°å¢)
        if volume_24h < ScoringConfig.MIN_VOLUME_24H:
            filtered_count += 1
            continue  # è·³è¿‡ä½äº¤æ˜“é‡ä»£å¸
        
        # 3. æ¢æ‰‹ç‡è¿‡æ»¤ (æ–°å¢: å‰”é™¤æ­»ç›˜)
        turnover = volume_24h / market_cap if market_cap > 0 else 0
        if turnover < ScoringConfig.MIN_TURNOVER:
            filtered_count += 1
            continue  # è·³è¿‡æ¢æ‰‹ç‡è¿‡ä½çš„ä»£å¸
        
        valid_crypto_list.append(crypto)
        
        # ä¿å­˜ä»Šæ—¥æ•°æ® (ä¸è¿‡æ»¤ï¼Œä¾¿äºåç»­è¶‹åŠ¿åˆ†æ)
        if volume_24h > 0 and price > 0:
            history_manager.update(today_str, symbol, {
                "volume": volume_24h,
                "price": price,
                "market_cap": market_cap
            })
            processed_symbols.append(symbol)
    
    print(f"è¿‡æ»¤åå‰©ä½™å…³æ³¨é¡¹ç›®: {len(valid_crypto_list)} (åŸ: {len(crypto_list)}, è¿‡æ»¤: {filtered_count})")
    print(f"å·²æ›´æ–° {len(processed_symbols)} ä¸ªé¡¹ç›®çš„ä»Šæ—¥æ•°æ®")
    
    # ============================================
    # é˜¶æ®µ2: åŸºäºä¸‰æ—¥æ•°æ®è¿›è¡Œè¶‹åŠ¿åˆ†æ
    # ============================================
    print("\né˜¶æ®µ2: ä¸‰æ—¥è¶‹åŠ¿åˆ†æ...")
    
    alerts = []
    dealer_accumulation_alerts = []  # å¸ç­¹: é‡å¢ä»·å¹³/å°æ¶¨
    dealer_distribution_alerts = []  # å‡ºè´§/æ´—ç›˜: é‡å¢ä»·è·Œ
    trend_signals = []  # ä¸‰æ—¥è¶‹åŠ¿ä¿¡å· (ç¨³å®šå¸ç­¹/æ´—ç›˜ç»“æŸ)
    
    for crypto in valid_crypto_list:  # ä½¿ç”¨è¿‡æ»¤åçš„åˆ—è¡¨
        symbol = crypto.get("symbol", "Unknown")
        name = crypto.get("name", "Unknown")
        
        quotes = crypto.get("quotes", [])
        usd_quote = next((q for q in quotes if q.get("name") == "USD"), {})
        if not usd_quote and len(quotes) > 2:
            usd_quote = quotes[2]
            
        if not usd_quote:
            continue

        vol_change_24h = usd_quote.get("volumePercentChange", 0)
        if vol_change_24h == 0:
            vol_change_24h = usd_quote.get("volumeChange24h", 0)
            
        price_change_24h = usd_quote.get("percentChange24h", 0)
        volume_24h = usd_quote.get("volume24h", 0)
        market_cap = usd_quote.get("marketCap", 0)
        price = usd_quote.get("price", 0)
        fullyDilluttedMarketCap = usd_quote.get("fullyDilluttedMarketCap", 0)
        platform = crypto.get("platform", {}).get("name", "")

        changes = {
            "24h": vol_change_24h,
            "7d": usd_quote.get("volumeChange7d", 0),
            "30d": usd_quote.get("volumeChange30d", 0)
        }
        
        triggered = []
        for period, change in changes.items():
            if abs(change) >= threshold:
                arrow = "â†‘" if change > 0 else "â†“"
                triggered.append(f"{arrow}{period}: {change:+.1f}%")
        
        # ============================================
        # ä¸‰æ—¥è¶‹åŠ¿åˆ†æ (æ ¸å¿ƒé€»è¾‘)
        # ============================================
        h_today = {"volume": volume_24h, "price": price, "market_cap": market_cap}
        
        # è¾…åŠ©å‡½æ•°: è·å–å†å²æ•°æ®
        def _get_history(idx_map, fallback_date):
            d_crypto = idx_map.get(symbol)
            if d_crypto:
                t_quotes = d_crypto.get("quotes", [])
                t_usd = next((q for q in t_quotes if q.get("name") == "USD"), {})
                if not t_usd and len(t_quotes) > 2:
                    t_usd = t_quotes[2]
                if t_usd:
                    return {
                        "volume": t_usd.get("volume24h", 0),
                        "price": t_usd.get("price", 0),
                        "market_cap": t_usd.get("marketCap", 0)
                    }
            return history_manager.get_data(symbol, fallback_date)

        h_yest = _get_history(t1_index, yesterday_str)
        h_before = _get_history(t2_index, day_before_str)
        h_t3 = _get_history(t3_index, three_days_ago_str)
        
        trend_signal = None
        is_continuous_accumulation = False
        
        # è¶‹åŠ¿åˆ†æåªçœ‹ T0-T2 (ä¿æŒç­–ç•¥é€»è¾‘ä¸å˜)
        if h_today and h_yest and h_before:
            history_analyze = [h_today, h_yest, h_before]
            trend_signal = DynamicTrendAnalyzer.analyze(history_analyze)
            
            # å¦‚æœæœ‰ T-3 æ•°æ®ï¼Œè¿½åŠ åˆ° history_3d åˆ—è¡¨ä¾›å±•ç¤ºä½¿ç”¨
            # è¿™æ˜¯ä¸€ä¸ªå…³é”® Hack: analyze è¿”å›çš„ history_3d åªæœ‰3ä¸ªï¼Œæˆ‘ä»¬è¿™é‡Œæ‰©å……ä¸º4ä¸ª
            if trend_signal and h_t3:
                 t3_turnover = h_t3.get("volume", 0) / h_t3.get("market_cap", 1) if h_t3.get("market_cap") else 0
                 trend_signal.history_3d.append({
                     "volume": h_t3.get("volume", 0),
                     "price": h_t3.get("price", 0),
                     "market_cap": h_t3.get("market_cap", 0),
                     "turnover": t3_turnover
                 })

            if trend_signal and trend_signal.signal_type != "NEUTRAL":
                should_alert = False
                if trend_signal.score >= 0.85:
                    should_alert = True
                elif trend_signal.score >= 0.75 and market_cap > 5_000_000:
                    should_alert = True
                
                if should_alert:
                    signal_data = {
                        "symbol": symbol,
                        "name": name,
                        "signal_type": trend_signal.signal_type,
                        "score": trend_signal.score,
                        "reason": trend_signal.reason,
                        "details": trend_signal.details,
                        "volume": volume_24h,
                        "market_cap": market_cap,
                        "fdv": fullyDilluttedMarketCap,
                        "platform": platform,
                        "price": price,
                        "price_change": price_change_24h,
                        "vol_change": vol_change_24h,
                        "history_3d": trend_signal.history_3d
                    }
                    trend_signals.append(signal_data)
                    
                    if trend_signal.signal_type == "ACCUMULATION_STABLE" and trend_signal.score > 0.8:
                        is_continuous_accumulation = True
        
        # ============================================
        # æ„å»ºä¸‰æ—¥å†å²æ•°æ® (ç”¨äºå±•ç¤º) - æ‰©å……ä¸º 4 å¤©
        # ============================================
        history_3d_enriched = None
        if h_today and h_yest and h_before:
            # è®¡ç®—æ¢æ‰‹ç‡
            raw_history = [h_today, h_yest, h_before]
            if h_t3:
                raw_history.append(h_t3)
                
            history_3d_enriched = []
            for d in raw_history:
                mc = d.get("market_cap", 0)
                vol = d.get("volume", 0)
                tr = vol / mc if mc > 0 else 0
                history_3d_enriched.append({
                    "volume": vol,
                    "price": d.get("price", 0),
                    "market_cap": mc,
                    "turnover": tr
                })
        
        # ============================================
        # åº„å®¶è¡Œä¸ºæ£€æµ‹ (å½“æ—¥ç»´åº¦ + ç½®ä¿¡åº¦åŠ æƒ)
        # ============================================
        is_accumulation = False
        current_turnover = volume_24h / market_cap if market_cap > 0 else 0
        
        if vol_change_24h > threshold and volume_24h >= MIN_VOLUME_24H:
            # è®¡ç®—åŠ¨æ€ç½®ä¿¡åº¦ (å³ä½¿ä¸æ˜¯ä¸‰æ—¥è¶‹åŠ¿ï¼Œå•æ—¥å¼‚åŠ¨ä¹Ÿå¯ä»¥æœ‰ç½®ä¿¡åº¦)
            base_alert_score = 0.65  # å•æ—¥å¼‚åŠ¨åŸºç¡€åˆ†
            alert_score, mcap_tag = ConfidenceEngine.calculate_score(
                base_alert_score, market_cap, current_turnover
            )
            score_emoji = ConfidenceEngine.get_score_emoji(alert_score)
            
            alert_data = {
                "symbol": symbol,
                "name": name,
                "vol_change": vol_change_24h,
                "price_change": price_change_24h,
                "volume": volume_24h,
                "market_cap": market_cap,
                "fdv": fullyDilluttedMarketCap,
                "platform": platform,
                "price": price,
                "history_3d": history_3d_enriched,  # æ·»åŠ æ•°æ®(å¯èƒ½åŒ…å«4å¤©)
                "score": alert_score,  # æ–°å¢åˆ†æ•°
                "mcap_tag": mcap_tag,  # æ–°å¢æ ‡ç­¾
                "score_emoji": score_emoji  # æ–°å¢ emoji
            }
            
            # åªæœ‰åˆ†æ•°è¾¾æ ‡æ‰åŠ å…¥è­¦æŠ¥
            if alert_score >= 0.55:
                # å¸ç­¹: é‡å¢ + ä»·æ ¼ä¸å˜æˆ–å°æ¶¨ (-2% ~ +10%)
                if -2 <= price_change_24h <= 10:
                    is_accumulation = True
                    
                    # æ ‡è®°è¿ç»­å¸ç­¹ (åŸºäºä¸‰æ—¥è¶‹åŠ¿åˆ†æç»“æœ)
                    if is_continuous_accumulation:
                        alert_data["is_continuous"] = True
                    # å¤‡ç”¨é€»è¾‘ï¼šç›´æ¥è®¡ç®—ä¸‰æ—¥ç¨³å®šæ€§
                    elif h_today and h_yest and h_before:
                        v_t, p_t = h_today["volume"], h_today["price"]
                        v_y, p_y = h_yest["volume"], h_yest["price"]
                        v_b, p_b = h_before["volume"], h_before["price"]
                        
                        vols = [v_t, v_y, v_b]
                        prices = [p_t, p_y, p_b]
                        v_stable = min(vols) >= max(vols) * 0.8
                        p_stable = max(prices) <= min(prices) * 1.05
                        
                        if v_stable and p_stable:
                            alert_data["is_continuous"] = True
                    
                    dealer_accumulation_alerts.append(alert_data)
                    
                # å‡ºè´§/æ´—ç›˜: é‡å¢ + ä»·æ ¼ä¸‹è·Œ (< -2%)
                elif price_change_24h < -2:
                    dealer_distribution_alerts.append(alert_data)

        if triggered:
            alert_info = {
                "symbol": symbol,
                "name": name,
                "change_24h": changes.get("24h", 0),
                "price_change": price_change_24h,
                "volume_24h": volume_24h,
                "is_accumulation": is_accumulation,
                "market_cap": market_cap,
                "fdv": fullyDilluttedMarketCap,
                "platform": platform,
                "history_3d": history_3d_enriched  # æ·»åŠ æ•°æ®(å¯èƒ½åŒ…å«4å¤©)
            }
            alerts.append(alert_info)
    
    # ä¿å­˜å†å²æ•°æ®
    history_manager.save()
    
    # ============================================
    # æ™ºèƒ½æ’åº (Sorting Optimization)
    # ============================================
    # ä¸å†å•çº¯æŒ‰å¸‚å€¼æ’åºï¼Œè€Œæ˜¯æŒ‰ [ç½®ä¿¡åº¦ desc, å¸‚å€¼ desc] æ’åº
    # è¿™æ · 10M-100M çš„é«˜åˆ†é¡¹ç›®ä¼šæ’åœ¨ 500M çš„æ™®é€šé¡¹ç›®å‰é¢
    
    def smart_sort_key(item):
        """æ™ºèƒ½æ’åºé”®: (ç½®ä¿¡åº¦, å¸‚å€¼)"""
        return (item.get("score", 0), item.get("market_cap", 0))
    
    # è¶‹åŠ¿ä¿¡å·æŒ‰ç½®ä¿¡åº¦å’Œå¸‚å€¼æ’åº
    trend_signals.sort(key=smart_sort_key, reverse=True)
    
    # å¸ç­¹å‘Šè­¦æŒ‰ç½®ä¿¡åº¦å’Œå¸‚å€¼æ’åº
    dealer_accumulation_alerts.sort(key=smart_sort_key, reverse=True)
    
    # å‡ºè´§/æ´—ç›˜å‘Šè­¦æŒ‰ç½®ä¿¡åº¦å’Œå¸‚å€¼æ’åº
    dealer_distribution_alerts.sort(key=smart_sort_key, reverse=True)
    
    # å¸¸è§„å¼‚åŠ¨æŒ‰24hå˜åŒ–ç‡æ’åº
    alerts.sort(key=lambda x: x["change_24h"], reverse=True)
    
    # ============================================
    # ä¼˜åŒ–: ä½¿ç”¨ SignalArbiter å®ç°"èµ¢å®¶é€šåƒ"å»é‡
    # ============================================
    arbiter = SignalArbiter()
    alpha_signals, anomaly_signals = arbiter.classify(
        trend_signals=trend_signals,
        accumulation_alerts=dealer_accumulation_alerts,
        distribution_alerts=dealer_distribution_alerts,
        volume_alerts=alerts
    )
    
    stats = arbiter.get_stats()
    print(f"\nğŸ“Š SignalArbiter åˆ†ç±»å®Œæˆ:")
    print(f"   ğŸ¯ Alpha ä¿¡å·: {stats['alpha_total']} ä¸ª {stats['alpha_by_type']}")
    print(f"   âš ï¸ å¼‚åŠ¨è­¦å‘Š: {stats['anomaly_total']} ä¸ª {stats['anomaly_by_type']}")
    print(f"   ğŸ“‹ å·²å¤„ç†ä»£å¸: {stats['processed_symbols']} ä¸ª")
    
    # ä¿å­˜å¸ç­¹/æ´—ç›˜æ•°æ®åˆ°æœ¬åœ° JSON (ä¾› docs-viewer ä½¿ç”¨)
    # ä» ClassifiedSignal æå–åŸå§‹æ•°æ®
    trend_for_save = [s.data for s in alpha_signals if s.category == SignalCategory.ALPHA_TREND]
    accum_for_save = [s.data for s in alpha_signals if s.category == SignalCategory.ALPHA_WHALE]
    dist_for_save = [s.data for s in anomaly_signals if s.category == SignalCategory.RISK_DISTRIBUTION]
    
    await _save_trend_data(
        trend_signals=trend_for_save,
        accumulation_alerts=accum_for_save,
        distribution_alerts=dist_for_save
    )

    # ============================================
    # é˜¶æ®µ3: å‘é€å‘Šè­¦ (åŒæµè¾“å‡º)
    # ============================================
    print("\né˜¶æ®µ3: å‘é€å‘Šè­¦ (åŒæµè¾“å‡º)...")
    
    # ğŸ¯ Alpha ä¿¡å·æµ (High Confidence Long Setup)
    if alpha_signals:
        print(f"ğŸ¯ å‘é€ Alpha ä¿¡å·: {len(alpha_signals)} ä¸ª")
        if not debug_only:
            await _send_unified_alpha(alpha_signals)
    
    # âš ï¸ å¼‚åŠ¨ä¸é£æ§æµ (Anomalies & Risks)
    if anomaly_signals:
        print(f"âš ï¸ å‘é€å¼‚åŠ¨è­¦å‘Š: {len(anomaly_signals)} ä¸ª")
        if not debug_only:
            # åœ¨ Alpha ä¸ é£é™©/å¼‚åŠ¨ æµä¹‹é—´æ’å…¥åˆ†éš”ç¬¦ï¼ˆä»…ä¸¤è€…éƒ½å­˜åœ¨æ—¶ï¼‰
            if alpha_signals:
                await send_discord_message("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
                await asyncio.sleep(0.3)
            await _send_unified_anomaly(anomaly_signals)
    
    if not alpha_signals and not anomaly_signals:
        print("æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„ä¿¡å·")
    
    return {
        "alpha_signals": [s.__dict__ for s in alpha_signals],
        "anomaly_signals": [s.__dict__ for s in anomaly_signals],
        "alpha_count": len(alpha_signals),
        "anomaly_count": len(anomaly_signals),
        "stats": stats
    }


class HistoryManager:
    """ç®¡ç†å†å²äº¤æ˜“é‡æ•°æ®"""
    def __init__(self, data_dir):
        self.file_path = os.path.join(data_dir, 'volume_monitor_history.json')
        self.history = self._load()

    def _load(self):
        if os.path.exists(self.file_path):
            try:
                with open(self.file_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logging.getLogger(__name__).error(f"åŠ è½½å†å²æ•°æ®å¤±è´¥: {e}")
                return {}
        return {}

    def save(self):
        try:
            with open(self.file_path, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logging.getLogger(__name__).error(f"ä¿å­˜å†å²æ•°æ®å¤±è´¥: {e}")

    def update(self, date_str, symbol, data):
        if symbol not in self.history:
            self.history[symbol] = {}
        self.history[symbol][date_str] = data
        
        # åªä¿ç•™æœ€è¿‘7å¤©
        dates = sorted(self.history[symbol].keys())
        if len(dates) > 7:
            for d in dates[:-7]:
                del self.history[symbol][d]

    def get_data(self, symbol, date_str):
        return self.history.get(symbol, {}).get(date_str)


def _format_number(num: float) -> str:
    """æ ¼å¼åŒ–æ•°å­—ï¼Œå¤§æ•°å­—ç”¨ K/M/B è¡¨ç¤º"""
    if abs(num) >= 1_000_000_000:
        return f"{num / 1_000_000_000:.1f}B"
    elif abs(num) >= 1_000_000:
        return f"{num / 1_000_000:.1f}M"
    elif abs(num) >= 1_000:
        return f"{num / 1_000:.1f}K"
    else:
        return f"{num:.0f}"




def _format_turnover(turnover: float) -> str:
    """æ ¼å¼åŒ–æ¢æ‰‹ç‡ (ç™¾åˆ†æ¯”å½¢å¼)"""
    if turnover <= 0:
        return "-"
    return f"{turnover * 100:.1f}%"


def _get_trend_emoji(values: list[float]) -> str:
    """æ ¹æ®æ•°å€¼è¶‹åŠ¿è¿”å› Emoji
    
    Args:
        values: æ•°å€¼åˆ—è¡¨ [æœ€æ–°, ..., æœ€æ—§]
        
    Returns:
        è¶‹åŠ¿ Emoji
    """
    if len(values) < 2:
        return "â¡ï¸"
    
    latest, prev = values[0], values[1]
    if prev == 0:
        return "â¡ï¸"
    
    change = (latest - prev) / prev * 100
    
    if change > 10:
        return "ğŸš€"
    elif change > 3:
        return "ğŸ“ˆ"
    elif change > -3:
        return "â¡ï¸"
    elif change > -10:
        return "ğŸ“‰"
    else:
        return "ğŸ’¥"


def _get_signal_color(signal_type: str) -> int:
    """è·å–ä¿¡å·ç±»å‹å¯¹åº”çš„é¢œè‰²
    
    Args:
        signal_type: ä¿¡å·ç±»å‹
        
    Returns:
        é¢œè‰²å€¼ (åå…­è¿›åˆ¶)
    """
    color_map = {
        "ACCUMULATION_STABLE": 0x9B59B6,  # ç´«è‰² - å¸ç­¹
        "WASH_COMPLETE": 0xF1C40F,         # é»„è‰² - æ´—ç›˜ç»“æŸ
        "BULL_FLAG": 0x2ECC71,             # ç»¿è‰² - ç‰›æ——
        "DISTRIBUTION": 0xE74C3C,          # çº¢è‰² - å‡ºè´§
    }
    return color_map.get(signal_type, 0x5865F2)


def _get_signal_emoji(signal_type: str) -> str:
    """è·å–ä¿¡å·ç±»å‹å¯¹åº”çš„ Emoji"""
    emoji_map = {
        "ACCUMULATION_STABLE": "ğŸŸª",
        "WASH_COMPLETE": "ğŸŸ¨",
        "BULL_FLAG": "ğŸŸ©",
        "DISTRIBUTION": "ğŸŸ¥",
    }
    return emoji_map.get(signal_type, "â¬œ")


def _get_signal_name(signal_type: str) -> str:
    """è·å–ä¿¡å·ç±»å‹çš„ä¸­æ–‡åç§°"""
    name_map = {
        "ACCUMULATION_STABLE": "ç¨³å®šå¸ç­¹",
        "WASH_COMPLETE": "æ´—ç›˜ç»“æŸ",
        "BULL_FLAG": "ç‰›æ——æ•´ç†",
        "DISTRIBUTION": "å‡ºè´§/æ´—ç›˜",
    }
    return name_map.get(signal_type, signal_type)




async def _send_embed_raw(embed: dict, username: str = "Binance Alpha Monitor"):
    """å‘é€åŸå§‹ Embed å¯¹è±¡
    
    Args:
        embed: Discord Embed å¯¹è±¡
        username: æœºå™¨äººåç§°
    """
    import aiohttp
    from config import DISCORD_WEBHOOK_URL, PROXY_URL, USE_PROXY
    
    if not DISCORD_WEBHOOK_URL:
        print("é”™è¯¯: DISCORD_WEBHOOK_URL æœªé…ç½®")
        return False
    
    payload = {"embeds": [embed]}
    if username:
        payload["username"] = username
    
    proxy = PROXY_URL if USE_PROXY else None
    headers = {"Content-Type": "application/json"}
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                DISCORD_WEBHOOK_URL,
                json=payload,
                headers=headers,
                proxy=proxy
            ) as response:
                if response.status in (200, 204):
                    print("Discord Embed æ¶ˆæ¯å‘é€æˆåŠŸ!")
                    return True
                else:
                    text = await response.text()
                    print(f"Discord Embed æ¶ˆæ¯å‘é€å¤±è´¥: {response.status}, {text}")
                    return False
    except Exception as e:
        print(f"Discord Embed æ¶ˆæ¯å‘é€å‡ºé”™: {str(e)}")
        return False




async def _save_trend_data(
    trend_signals: list[dict],
    accumulation_alerts: list[dict],
    distribution_alerts: list[dict]
):
    """ä¿å­˜å¸ç­¹/æ´—ç›˜æ•°æ®åˆ°æœ¬åœ° JSON æ–‡ä»¶ (ä¾› docs-viewer ä½¿ç”¨)
    
    è¾“å‡ºè·¯å¾„: data/trend_signals_YYYYMMDD.json
    (é€šè¿‡ generate-list.js è„šæœ¬å¤åˆ¶åˆ° docs-viewer/public/tables/)
    
    Args:
        trend_signals: ä¸‰æ—¥è¶‹åŠ¿ä¿¡å·åˆ—è¡¨
        accumulation_alerts: å¸ç­¹å‘Šè­¦åˆ—è¡¨
        distribution_alerts: å‡ºè´§/æ´—ç›˜å‘Šè­¦åˆ—è¡¨
    """
    # ç›®æ ‡ç›®å½• (ä¿å­˜åˆ° data ç›®å½•ï¼Œä¸ filtered_crypto_list åŒçº§)
    data_dir = os.path.join(project_root, 'data')
    if not os.path.exists(data_dir):
        logger.warning(f"data ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜: {data_dir}")
        return
    
    today_str = datetime.now().strftime('%Y%m%d')
    output_file = os.path.join(data_dir, f'trend_signals_{today_str}.json')
    
    # æ„å»ºè¾“å‡ºæ•°æ®ç»“æ„
    output_data = {
        "title": "å¸ç­¹/æ´—ç›˜ä¿¡å·åˆ†æ",
        "date": datetime.now().strftime('%Y-%m-%d'),
        "generated_at": datetime.now().isoformat(),
        "summary": {
            "trend_signals_count": len(trend_signals),
            "accumulation_count": len(accumulation_alerts),
            "distribution_count": len(distribution_alerts)
        },
        "columns": [
            "ä»£å·", "åç§°", "ä¿¡å·ç±»å‹", "ç½®ä¿¡åº¦", "å¸‚å€¼åˆ†å±‚", "å¸‚å€¼æ ‡ç­¾", "äº¤æ˜“é‡å˜åŒ–(%)", "ä»·æ ¼å˜åŒ–(%)",
            "24häº¤æ˜“é‡", "å¸‚å€¼", "FDV", "å¹³å°", "ä¿¡å·è§£è¯»",
            "T0äº¤æ˜“é‡", "T0æ¢æ‰‹ç‡", "T-1äº¤æ˜“é‡", "T-1æ¢æ‰‹ç‡", "T-2äº¤æ˜“é‡", "T-2æ¢æ‰‹ç‡"
        ],
        "data": []
    }
    
    # åˆå¹¶æ‰€æœ‰ä¿¡å·æ•°æ®
    all_items = []
    
    # æ·»åŠ ä¸‰æ—¥è¶‹åŠ¿ä¿¡å·
    for item in trend_signals:
        signal_type = item.get("signal_type", "UNKNOWN")
        signal_name = _get_signal_name(signal_type)
        history_3d = item.get("history_3d", [])
        
        details = item.get("details", {}) or {}
        tier_name = details.get("tier", "-")
        mcap_tag = details.get("mcap_tag", "-")
        row = {
            "ä»£å·": item.get("symbol", "-"),
            "åç§°": item.get("name", "-"),
            "ä¿¡å·ç±»å‹": signal_name,
            "ç½®ä¿¡åº¦": f"{item.get('score', 0):.2f}",
            "å¸‚å€¼åˆ†å±‚": tier_name,
            "å¸‚å€¼æ ‡ç­¾": mcap_tag,
            "äº¤æ˜“é‡å˜åŒ–(%)": f"{item.get('vol_change', 0):+.1f}%",
            "ä»·æ ¼å˜åŒ–(%)": f"{item.get('price_change', 0):+.1f}%",
            "24häº¤æ˜“é‡": f"${_format_number(item.get('volume', 0))}",
            "å¸‚å€¼": f"${_format_number(item.get('market_cap', 0))}",
            "FDV": f"${_format_number(item.get('fdv', 0))}",
            "å¹³å°": item.get("platform", "-"),
            "ä¿¡å·è§£è¯»": item.get("reason", "-"),
            "signal_type_raw": signal_type,
            "score_raw": item.get("score", 0),
            "tier_raw": tier_name,
            "mcap_tag_raw": mcap_tag,
            "vol_change_raw": item.get("vol_change", 0),
            "price_change_raw": item.get("price_change", 0),
            "volume_raw": item.get("volume", 0),
            "market_cap_raw": item.get("market_cap", 0),
        }
        
        # ä¸‰æ—¥æ•°æ®
        if history_3d and len(history_3d) >= 3:
            for i, label in enumerate(["T0", "T-1", "T-2"]):
                d = history_3d[i]
                row[f"{label}äº¤æ˜“é‡"] = f"${_format_number(d.get('volume', 0))}"
                row[f"{label}æ¢æ‰‹ç‡"] = _format_turnover(d.get("turnover", 0))
                row[f"{label}_volume_raw"] = d.get("volume", 0)
                row[f"{label}_turnover_raw"] = d.get("turnover", 0)
        else:
            for label in ["T0", "T-1", "T-2"]:
                row[f"{label}äº¤æ˜“é‡"] = "-"
                row[f"{label}æ¢æ‰‹ç‡"] = "-"
        
        all_items.append(row)
    
    # æ·»åŠ å¸ç­¹å‘Šè­¦ (å¦‚æœä¸åœ¨ trend_signals ä¸­)
    existing_symbols = {item["ä»£å·"] for item in all_items}
    for item in accumulation_alerts:
        symbol = item.get("symbol", "-")
        if symbol in existing_symbols:
            continue
        
        history_3d = item.get("history_3d", [])
        score = item.get("score", 0.70 if not item.get("is_continuous") else 0.85)
        mcap_tag = item.get("mcap_tag", "-")
        
        # è®¡ç®—å¸‚å€¼åˆ†å±‚
        market_cap = item.get("market_cap", 0)
        if market_cap >= 100_000_000:
            tier_name = "LARGE"
        elif market_cap >= 10_000_000:
            tier_name = "MID"
        elif market_cap >= 5_000_000:
            tier_name = "SMALL"
        else:
            tier_name = "MICRO"
        
        row = {
            "ä»£å·": symbol,
            "åç§°": item.get("name", "-"),
            "ä¿¡å·ç±»å‹": "ç–‘ä¼¼å¸ç­¹" if not item.get("is_continuous") else "æŒç»­å¸ç­¹",
            "ç½®ä¿¡åº¦": f"{score:.2f}",
            "å¸‚å€¼åˆ†å±‚": tier_name,
            "å¸‚å€¼æ ‡ç­¾": mcap_tag,
            "äº¤æ˜“é‡å˜åŒ–(%)": f"{item.get('vol_change', 0):+.1f}%",
            "ä»·æ ¼å˜åŒ–(%)": f"{item.get('price_change', 0):+.1f}%",
            "24häº¤æ˜“é‡": f"${_format_number(item.get('volume', 0))}",
            "å¸‚å€¼": f"${_format_number(item.get('market_cap', 0))}",
            "FDV": f"${_format_number(item.get('fdv', 0))}",
            "å¹³å°": item.get("platform", "-"),
            "ä¿¡å·è§£è¯»": "é‡å¢ä»·å¹³/å°æ¶¨" + (" + è¿ç»­3æ—¥ç¨³å®š" if item.get("is_continuous") else "") + f" {mcap_tag}",
            "signal_type_raw": "ACCUMULATION_SINGLE" if not item.get("is_continuous") else "ACCUMULATION_CONTINUOUS",
            "score_raw": score,
            "tier_raw": tier_name,
            "mcap_tag_raw": mcap_tag,
            "vol_change_raw": item.get("vol_change", 0),
            "price_change_raw": item.get("price_change", 0),
            "volume_raw": item.get("volume", 0),
            "market_cap_raw": item.get("market_cap", 0),
        }
        
        if history_3d and len(history_3d) >= 3:
            for i, label in enumerate(["T0", "T-1", "T-2"]):
                d = history_3d[i]
                row[f"{label}äº¤æ˜“é‡"] = f"${_format_number(d.get('volume', 0))}"
                row[f"{label}æ¢æ‰‹ç‡"] = _format_turnover(d.get("turnover", 0))
                row[f"{label}_volume_raw"] = d.get("volume", 0)
                row[f"{label}_turnover_raw"] = d.get("turnover", 0)
        else:
            for label in ["T0", "T-1", "T-2"]:
                row[f"{label}äº¤æ˜“é‡"] = "-"
                row[f"{label}æ¢æ‰‹ç‡"] = "-"
        
        all_items.append(row)
        existing_symbols.add(symbol)
    
    # æ·»åŠ å‡ºè´§/æ´—ç›˜å‘Šè­¦
    for item in distribution_alerts:
        symbol = item.get("symbol", "-")
        if symbol in existing_symbols:
            continue
        
        history_3d = item.get("history_3d", [])
        score = item.get("score", 0.65)
        mcap_tag = item.get("mcap_tag", "-")
        
        # è®¡ç®—å¸‚å€¼åˆ†å±‚
        market_cap = item.get("market_cap", 0)
        if market_cap >= 100_000_000:
            tier_name = "LARGE"
        elif market_cap >= 10_000_000:
            tier_name = "MID"
        elif market_cap >= 5_000_000:
            tier_name = "SMALL"
        else:
            tier_name = "MICRO"
        
        row = {
            "ä»£å·": symbol,
            "åç§°": item.get("name", "-"),
            "ä¿¡å·ç±»å‹": "ç–‘ä¼¼å‡ºè´§/æ´—ç›˜",
            "ç½®ä¿¡åº¦": f"{score:.2f}",
            "å¸‚å€¼åˆ†å±‚": tier_name,
            "å¸‚å€¼æ ‡ç­¾": mcap_tag,
            "äº¤æ˜“é‡å˜åŒ–(%)": f"{item.get('vol_change', 0):+.1f}%",
            "ä»·æ ¼å˜åŒ–(%)": f"{item.get('price_change', 0):+.1f}%",
            "24häº¤æ˜“é‡": f"${_format_number(item.get('volume', 0))}",
            "å¸‚å€¼": f"${_format_number(item.get('market_cap', 0))}",
            "FDV": f"${_format_number(item.get('fdv', 0))}",
            "å¹³å°": item.get("platform", "-"),
            "ä¿¡å·è§£è¯»": f"é‡å¢ä»·è·Œï¼Œæ³¨æ„é£é™© {mcap_tag}",
            "signal_type_raw": "DISTRIBUTION",
            "score_raw": score,
            "tier_raw": tier_name,
            "mcap_tag_raw": mcap_tag,
            "vol_change_raw": item.get("vol_change", 0),
            "price_change_raw": item.get("price_change", 0),
            "volume_raw": item.get("volume", 0),
            "market_cap_raw": item.get("market_cap", 0),
        }
        
        if history_3d and len(history_3d) >= 3:
            for i, label in enumerate(["T0", "T-1", "T-2"]):
                d = history_3d[i]
                row[f"{label}äº¤æ˜“é‡"] = f"${_format_number(d.get('volume', 0))}"
                row[f"{label}æ¢æ‰‹ç‡"] = _format_turnover(d.get("turnover", 0))
                row[f"{label}_volume_raw"] = d.get("volume", 0)
                row[f"{label}_turnover_raw"] = d.get("turnover", 0)
        else:
            for label in ["T0", "T-1", "T-2"]:
                row[f"{label}äº¤æ˜“é‡"] = "-"
                row[f"{label}æ¢æ‰‹ç‡"] = "-"
        
        all_items.append(row)
    
    # æŒ‰ç½®ä¿¡åº¦å’Œå¸‚å€¼æ’åº
    all_items.sort(key=lambda x: (x.get("score_raw", 0), x.get("market_cap_raw", 0)), reverse=True)
    output_data["data"] = all_items
    output_data["total_count"] = len(all_items)
    
    # å†™å…¥æ–‡ä»¶
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        logger.info(f"å·²ä¿å­˜å¸ç­¹/æ´—ç›˜æ•°æ®åˆ°: {output_file}, å…± {len(all_items)} æ¡")
    except Exception as e:
        logger.error(f"ä¿å­˜å¸ç­¹/æ´—ç›˜æ•°æ®å¤±è´¥: {e}")


# ==============================================================================
# ç»Ÿä¸€æ¨é€å‡½æ•° (Unified Notification System)
# åªæœ‰ä¸¤æ¡æ•°æ®æµï¼šğŸ¯ Alpha + âš ï¸ å¼‚åŠ¨
# ==============================================================================

async def _send_unified_alpha(signals: list[ClassifiedSignal], max_per_embed: int = 5):
    """å‘é€ ğŸ¯ Alpha ä¿¡å·æµ
    
    ç»Ÿä¸€ä½¿ç”¨ Embed æ ¼å¼ï¼ŒæŒ‰å­ç±»å‹åˆ†ç»„ï¼Œç´§å‡‘å±•ç¤ºã€‚
    
    Args:
        signals: ClassifiedSignal åˆ—è¡¨
        max_per_embed: æ¯ä¸ª Embed æœ€å¤šå±•ç¤ºå¤šå°‘ä¸ª
    """
    if not signals:
        return
    
    # æŒ‰å­ç±»å‹åˆ†ç»„
    by_subtype: dict[str, list[ClassifiedSignal]] = {}
    for s in signals:
        if s.sub_type not in by_subtype:
            by_subtype[s.sub_type] = []
        by_subtype[s.sub_type].append(s)
    
    # å®šä¹‰å­ç±»å‹çš„å±•ç¤ºé¡ºåºå’Œé…ç½®
    subtype_config = {
        "ACCUMULATION_STABLE": {"title": "ğŸ¯ Alpha: ç¨³å®šå¸ç­¹", "color": 0x9B59B6, "desc": "è¿ç»­3æ—¥é‡èƒ½ç¨³å®š + ä»·æ ¼æ¨ªç›˜"},
        "WASH_COMPLETE": {"title": "ğŸ¯ Alpha: æ´—ç›˜ç»“æŸ", "color": 0xF1C40F, "desc": "è¿ç»­ç¼©é‡ + ä»·æ ¼ä¼ç¨³ï¼Œå–ç›˜æ¯ç«­"},
        "BULL_FLAG": {"title": "ğŸ¯ Alpha: ç‰›æ——æ•´ç†", "color": 0x2ECC71, "desc": "æ˜¨æ—¥æ”¾é‡å¤§æ¶¨ + ä»Šæ—¥ç¼©é‡å›è°ƒ"},
        "ACCUMULATION_WHALE": {"title": "ğŸ¯ Alpha: å·¨é²¸å¸ç­¹", "color": 0x3498DB, "desc": "é«˜ç½®ä¿¡åº¦èµ„é‡‘æµå…¥ (é‡å¢ä»·å¹³)"},
    }
    
    # æŒ‰é¡ºåºå‘é€
    for subtype in ["WASH_COMPLETE", "ACCUMULATION_STABLE", "BULL_FLAG", "ACCUMULATION_WHALE"]:
        group = by_subtype.get(subtype, [])
        if not group:
            continue
        
        config = subtype_config.get(subtype, {"title": f"ğŸ¯ Alpha: {subtype}", "color": 0x5865F2, "desc": ""})
        await _send_compact_embed(
            title=config["title"],
            signals=group[:max_per_embed],
            total_count=len(group),
            color=config["color"],
            description=config["desc"]
        )
        await asyncio.sleep(0.3)


async def _send_unified_anomaly(signals: list[ClassifiedSignal], max_per_embed: int = 5):
    """å‘é€ âš ï¸ å¼‚åŠ¨ä¸é£æ§æµ
    
    ç»Ÿä¸€ä½¿ç”¨ Embed æ ¼å¼ï¼Œåˆ†ä¸ºå‡ºè´§é£é™©å’Œæç«¯å¼‚åŠ¨ä¸¤éƒ¨åˆ†ã€‚
    
    Args:
        signals: ClassifiedSignal åˆ—è¡¨
        max_per_embed: æ¯ä¸ª Embed æœ€å¤šå±•ç¤ºå¤šå°‘ä¸ª
    """
    if not signals:
        return
    
    # åˆ†ç»„
    distribution = [s for s in signals if s.category == SignalCategory.RISK_DISTRIBUTION]
    extreme = [s for s in signals if s.category == SignalCategory.ANOMALY_EXTREME]
    
    # å‡ºè´§é£é™©
    if distribution:
        await _send_compact_embed(
            title="âš ï¸ é£é™©: ä¸»åŠ›å‡ºè´§",
            signals=distribution[:max_per_embed],
            total_count=len(distribution),
            color=0xE74C3C,  # çº¢è‰²
            description="é‡å¢ä»·è·Œï¼Œæ³¨æ„è§„é¿ä¸‹è·Œé£é™©"
        )
        await asyncio.sleep(0.3)
    
    # æç«¯å¼‚åŠ¨ (åŒ…æ‹¬ä½åˆ†å¸ç­¹å’Œæç«¯çˆ†é‡)
    if extreme:
        await _send_compact_embed(
            title="âš ï¸ å¼‚åŠ¨: æç«¯æ³¢åŠ¨",
            signals=extreme[:max_per_embed],
            total_count=len(extreme),
            color=0xE67E22,  # æ©™è‰²
            description="æç«¯äº¤æ˜“é‡å˜åŒ–ï¼Œé«˜é£é™©é«˜æ”¶ç›Š"
        )


async def _send_compact_embed(
    title: str,
    signals: list[ClassifiedSignal],
    total_count: int,
    color: int,
    description: str = ""
):
    """å‘é€ç´§å‡‘æ ¼å¼çš„ Embed (æ”¯æŒåˆ†é¡µä¸è¯¦ç»†3æ—¥æ•°æ®)
    
    æ ¼å¼:
    Symbol (Name)
    ğŸ’µ $Price | ğŸ’° MC $... | FDV $...
    Vol +X% ğŸš€ | Price +Y% ğŸ“ˆ | Score 0.XX
    T-0: vol/price-change/TR
    T-1: ...
    T-2: ...
    
    Args:
        title: Embed æ ‡é¢˜
        signals: ä¿¡å·åˆ—è¡¨
        total_count: æ€»æ•°é‡ (å¿½ç•¥ï¼Œå®é™…ä½¿ç”¨ signals é•¿åº¦)
        color: é¢œè‰²
        description: æè¿°æ–‡æœ¬
    """
    if not signals:
        return
    
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    real_count = len(signals)
    
    # æ„é€ å¤´éƒ¨ä¿¡æ¯ (Total Count & Time)
    header_title = f"{title} ({real_count}ä¸ª)"
    header_description = f"â±ï¸ {current_time}"
    if description:
        header_description += f"\n{description}"
        
    # åˆ†é¡µé…ç½®
    MAX_FIELDS_PER_EMBED = 10  # æ¯ä¸ª Embed æœ€å¤šæ˜¾ç¤ºå¤šå°‘ä¸ªä»£å¸ (é˜²æ­¢æ¶ˆæ¯è¿‡é•¿)
    chunks = [signals[i:i + MAX_FIELDS_PER_EMBED] for i in range(0, len(signals), MAX_FIELDS_PER_EMBED)]
    
    total_chunks = len(chunks)
    
    for chunk_idx, chunk in enumerate(chunks):
        fields = []
        
        for i, sig in enumerate(chunk, 1):
            # å…¨å±€åºå·
            global_idx = chunk_idx * MAX_FIELDS_PER_EMBED + i
            
            data = sig.data
            symbol = sig.symbol
            name = sig.name[:12]
            
            # æå–å…³é”®æ•°æ®
            price = data.get("price", 0)
            market_cap = data.get("market_cap", 0)
            fdv = data.get("fdv", 0)
            vol_change = data.get("vol_change", data.get("change_24h", 0))
            price_change = data.get("price_change", 0)
            history_3d = data.get("history_3d", [])

            # ä»·æ ¼å›å¡«
            if (not price or price <= 0) and history_3d and isinstance(history_3d, list):
                try:
                    t0_price = history_3d[0].get("price", 0) if len(history_3d) >= 1 else 0
                    if t0_price and t0_price > 0:
                        price = t0_price
                except Exception:
                    pass
            
            # æ ¼å¼åŒ–åŸºç¡€æ•°å€¼
            price_str = f"${price:.6g}" if price > 0 else "-"
            mc_str = _format_number(market_cap)
            fdv_str = _format_number(fdv)
            
            # Emoji
            vol_emoji = "ğŸš€" if vol_change > 50 else "ğŸ“ˆ" if vol_change > 0 else "ğŸ“‰"
            price_emoji = "ğŸ“ˆ" if price_change > 3 else "ğŸ“‰" if price_change < -3 else "â¡ï¸"
            score_emoji = ConfidenceEngine.get_score_emoji(sig.score)

            # æ„å»º 3æ—¥æ•°æ®è¯¦æƒ… (T-0, T-1, T-2)
            metrics_lines = []
            if history_3d and isinstance(history_3d, list):
                # è¾…åŠ©å‡½æ•°: å®‰å…¨è·å–æ•°æ®
                def _get_h_data(idx):
                    if idx < len(history_3d):
                        return history_3d[idx] or {}
                    return {}
                
                t0, t1, t2 = _get_h_data(0), _get_h_data(1), _get_h_data(2)
                
                # å®šä¹‰è¡Œç”Ÿæˆé€»è¾‘
                days = [("T-0", t0), ("T-1", t1), ("T-2", t2)]
                
                # è®¡ç®—ä»·æ ¼å˜åŒ–éœ€è¦çš„ä¸Šæ—¥ä»·æ ¼
                # T-0 PChg = (P0 - P1)/P1
                # T-1 PChg = (P1 - P2)/P2
                # T-2 PChg = (P2 - P3)/P3 (å¦‚æœä¸å­˜åœ¨P3åˆ™æ— æ³•è®¡ç®—)
                
                # è·å–ä»·æ ¼åºåˆ—ç”¨äºè®¡ç®—æ¶¨è·Œå¹…
                p0 = t0.get("price", 0) or 0
                p1 = t1.get("price", 0) or 0
                p2 = t2.get("price", 0) or 0
                # å°è¯•è·å– t3 ç”¨äºè®¡ç®— t2 çš„æ¶¨è·Œå¹… (å¦‚æœå­˜åœ¨)
                t3 = _get_h_data(3)
                p3 = t3.get("price", 0) or 0
                
                prices_seq = [p0, p1, p2, p3]
                
                for d_idx, (label, day_data) in enumerate(days):
                    if not day_data:
                        continue
                        
                    vol = day_data.get("volume", 0) or 0
                    
                    # æ¢æ‰‹ç‡
                    tr = day_data.get("turnover", 0)
                    if not tr and market_cap > 0:
                         # ä¼°ç®—: ä½¿ç”¨å½“å¤©çš„ MC ä¼°ç®— (ä¸å¤ªå‡†ï¼Œä½†å¯ç”¨)
                         tr = vol / market_cap
                    
                    # ä»·æ ¼å˜åŒ–
                    # æ³¨æ„: prices_seq é•¿åº¦ä¸º 4 (p0, p1, p2, p3), d_idx æœ€å¤§ä¸º 2 (T-2)
                    # å½“ d_idx=2 (T-2) æ—¶, prev_p æ˜¯ p3
                    curr_p = prices_seq[d_idx]
                    prev_p = prices_seq[d_idx + 1] if d_idx + 1 < len(prices_seq) else 0
                    
                    pchg_str = "-"
                    if prev_p > 0:
                        pchg = (curr_p - prev_p) / prev_p * 100
                        pchg_str = f"{pchg:+.1f}%"
                    
                    # æ ¼å¼åŒ–å•è¡Œ
                    # T-X: vol / price-change / TR
                    line = f"{label}: ${_format_number(vol)} / {pchg_str} / TR {_format_turnover(tr)}"
                    metrics_lines.append(line)
            
            # æ„å»º field
            field_name = f"{global_idx}. {symbol} ({name})"
            reason_line = (sig.reason or "").strip() or "-"
            
            content_lines = [
                f"ğŸ’µ **{price_str}** | ğŸ’° MC ${mc_str} | FDV ${fdv_str}",
                f"Vol {vol_change:+.0f}% {vol_emoji} | Price {price_change:+.1f}% {price_emoji} | {sig.score:.2f} {score_emoji}",
            ]
            if metrics_lines:
                content_lines.extend(metrics_lines)
            content_lines.append(f"ğŸ’¡ {reason_line}")

            fields.append({
                "name": field_name,
                "value": "\n".join(content_lines),
                "inline": False
            })
        
        # å‘é€å½“å‰ chunk
        chunk_title = header_title
        if total_chunks > 1:
            chunk_title = f"{header_title} ({chunk_idx + 1}/{total_chunks})"
        
        # åº•éƒ¨ä¸å†é‡å¤æ˜¾ç¤ºæ—¶é—´å’Œæ€»æ•°
        footer_text = "Binance Alpha Monitor"
        
        embed = {
            "title": chunk_title,
            "description": header_description if chunk_idx == 0 else "", # æè¿°åªæ˜¾ç¤ºåœ¨ç¬¬ä¸€é¡µ
            "color": color,
            "fields": fields,
            "footer": {"text": footer_text}
        }
        
        await _send_embed_raw(embed)
        # é¿å…é€Ÿç‡é™åˆ¶
        if total_chunks > 1:
            await asyncio.sleep(0.5)

async def get_volume_statistics(crypto_list):
    """è·å–äº¤æ˜“é‡ç»Ÿè®¡ä¿¡æ¯ (ä¿ç•™åŸæœ‰åŠŸèƒ½)"""
    total_volume_24h = 0
    volume_changes = []
    
    for crypto in crypto_list:
        quotes = crypto.get("quotes", [])
        usd_quote = next((q for q in quotes if q.get("name") == "USD"), {})
        if not usd_quote and len(quotes) > 2:
            usd_quote = quotes[2]
        
        volume_24h = usd_quote.get("volume24h", 0)
        vol_change = usd_quote.get("volumePercentChange", 0)
        
        total_volume_24h += volume_24h
        if vol_change != 0:
            volume_changes.append({
                "symbol": crypto.get("symbol", "Unknown"),
                "name": crypto.get("name", "Unknown"),
                "volume_24h": volume_24h,
                "change_24h": vol_change
            })
    
    # æŒ‰æ¶¨å¹…æ’åº
    volume_changes.sort(key=lambda x: x["change_24h"], reverse=True)
    
    return {
        "total_volume_24h": total_volume_24h,
        "top_gainers": volume_changes[:10] if volume_changes else [],
        "top_losers": volume_changes[-10:][::-1] if volume_changes else [],
        "average_change": sum(v["change_24h"] for v in volume_changes) / len(volume_changes) if volume_changes else 0
    }

async def main():
    """ç‹¬ç«‹è¿è¡Œå…¥å£"""
    import argparse
    parser = argparse.ArgumentParser(description="äº¤æ˜“é‡ç›‘æ§å·¥å…·")
    parser.add_argument("--threshold", type=float, default=50.0, help="äº¤æ˜“é‡å˜åŒ–é˜ˆå€¼ (%)")
    parser.add_argument("--debug", action="store_true", help="è°ƒè¯•æ¨¡å¼ï¼Œä¸å‘é€æ¶ˆæ¯")
    args = parser.parse_args()
    
    await monitor_volume_changes(threshold=args.threshold, debug_only=args.debug)

if __name__ == "__main__":
    asyncio.run(main())



